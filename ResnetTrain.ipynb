{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Input, Reshape\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import Dataloader\n",
    "import ImageResize\n",
    "from keras.preprocessing import image\n",
    "import models as models\n",
    "import importlib\n",
    "importlib.reload(models)\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels), my_dict = Dataloader.load_data()\n",
    "\n",
    "train_images = tf.keras.utils.normalize(train_images, axis=1)\n",
    "test_images = tf.keras.utils.normalize(test_images, axis=1)\n",
    "num_classes = 46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 32, 32)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 32, 32, 1)    0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 28, 28, 4)    104         reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 14, 14, 4)    0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 14, 14, 4)    148         max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 14, 14, 4)    16          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 14, 14, 4)    0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 14, 14, 4)    148         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 14, 14, 4)    16          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 14, 14, 4)    0           batch_normalization_2[0][0]      \n",
      "                                                                 max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 14, 14, 4)    0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 14, 14, 4)    148         activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 14, 14, 4)    16          conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 14, 14, 4)    0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 14, 14, 4)    148         activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 14, 14, 4)    16          conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 14, 14, 4)    0           batch_normalization_4[0][0]      \n",
      "                                                                 activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 14, 14, 4)    0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 14, 14, 8)    40          activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 14, 14, 8)    584         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 14, 14, 8)    32          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 14, 14, 8)    0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 14, 14, 8)    584         activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 14, 14, 8)    32          conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 14, 14, 8)    0           batch_normalization_6[0][0]      \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 14, 14, 8)    0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 8)      0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 392)          0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          50304       flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           8256        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 46)           2990        dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 63,582\n",
      "Trainable params: 63,518\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = models.badass_network()\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                optimizer=keras.optimizers.Adadelta(),\n",
    "                metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.convolutional_neural_network()\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "                optimizer=keras.optimizers.Adadelta(),\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_2 (Reshape)          (None, 32, 32, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 30, 30, 8)         80        \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 28, 28, 16)        1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                100384    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 47)                1551      \n",
      "=================================================================\n",
      "Total params: 103,183\n",
      "Trainable params: 103,183\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 78200 samples, validate on 13800 samples\n",
      "Epoch 1/5\n",
      "78200/78200 [==============================] - 61s 777us/step - loss: 0.8773 - acc: 0.7533 - val_loss: 0.3422 - val_acc: 0.9012\n",
      "Epoch 2/5\n",
      "78200/78200 [==============================] - 63s 805us/step - loss: 0.3419 - acc: 0.8991 - val_loss: 0.2366 - val_acc: 0.9312\n",
      "Epoch 3/5\n",
      "78200/78200 [==============================] - 55s 705us/step - loss: 0.2539 - acc: 0.9245 - val_loss: 0.2094 - val_acc: 0.9365\n",
      "Epoch 4/5\n",
      "78200/78200 [==============================] - 64s 812us/step - loss: 0.2108 - acc: 0.9370 - val_loss: 0.1766 - val_acc: 0.9478\n",
      "Epoch 5/5\n",
      "78200/78200 [==============================] - 68s 871us/step - loss: 0.1795 - acc: 0.9468 - val_loss: 0.1634 - val_acc: 0.9521\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10e01ad68>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels,\n",
    "        epochs=5,\n",
    "        verbose=1,\n",
    "        shuffle=True,\n",
    "        validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13800/13800 [==============================] - 3s 215us/step\n",
      "Test loss: 0.1634364715638314\n",
      "Test accuracy: 0.9521014492753623\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_images, test_labels, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('resnet_handwriting.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "test_img = ImageResize.resizeImage('TestImage/ka.png')\n",
    "print(test_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "क\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('resnet_handwriting.h5', compile=False)\n",
    "predictions = model.predict(test_img)\n",
    "predicted_class = np.argmax(predictions[0])\n",
    "print(my_dict.get(predicted_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image, ImageFilter,ImageOps\n",
    "test_image = image.load_img('TestImage/kha2.png', target_size = (32,32), color_mode=\"grayscale\")\n",
    "test_image = ImageOps.invert(test_image)\n",
    "test_image = tf.keras.utils.normalize(test_image, axis=1)\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = test_image.reshape((test_image.shape[0], -1), order='F')\n",
    "plt.imshow(test_image, cmap='Greys')\n",
    "test_image = np.expand_dims(test_image, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
